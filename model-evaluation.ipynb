{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11256986,"sourceType":"datasetVersion","datasetId":7035227}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TEST ACCURACY OF OUR FINE-TUNED MODEL","metadata":{}},{"cell_type":"code","source":"%%capture\n\n!pip install unsloth # install unsloth\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git # Also get the latest version Unsloth!","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T04:37:21.447642Z","iopub.execute_input":"2025-04-03T04:37:21.447950Z","iopub.status.idle":"2025-04-03T04:40:42.184300Z","shell.execute_reply.started":"2025-04-03T04:37:21.447924Z","shell.execute_reply":"2025-04-03T04:40:42.183173Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"%%capture\n\n!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T04:40:42.185574Z","iopub.execute_input":"2025-04-03T04:40:42.185856Z","iopub.status.idle":"2025-04-03T04:40:46.544150Z","shell.execute_reply.started":"2025-04-03T04:40:42.185829Z","shell.execute_reply":"2025-04-03T04:40:46.543030Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nfrom unsloth import is_bfloat16_supported\nimport torch\nimport evaluate  # Updated from `load_metric`\nimport pandas as pd\nfrom tqdm import tqdm  # For progress tracking\nfrom datasets import load_dataset, DatasetDict\nfrom transformers import AutoTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T05:36:00.322350Z","iopub.execute_input":"2025-04-03T05:36:00.322680Z","iopub.status.idle":"2025-04-03T05:36:00.327037Z","shell.execute_reply.started":"2025-04-03T05:36:00.322657Z","shell.execute_reply":"2025-04-03T05:36:00.326155Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"model_name = \"aaditya-vaid/Llama-3.2-3B-Fine-Tuned-IMDB10K\"\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name,\n    max_seq_length=512,  \n    dtype=torch.float16,  \n    attn_implementation=\"flash_attention_2\"\n)\nmodel.eval()\nFastLanguageModel.for_inference(model)  # Enable faster inference","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T04:41:24.018473Z","iopub.execute_input":"2025-04-03T04:41:24.018817Z","iopub.status.idle":"2025-04-03T04:41:46.321114Z","shell.execute_reply.started":"2025-04-03T04:41:24.018789Z","shell.execute_reply":"2025-04-03T04:41:46.320206Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n   \\\\   /|    Tesla P100-PCIE-16GB. Num GPUs = 1. Max memory: 15.888 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 6.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.35G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ea003db0acc49f79900eac125a0254e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82f791123b24416793e4be6841ce1b8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b66e8e895f0472988f07f79ac43d828"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"681643e14ada46069e5d814eb0ed0ceb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95cc5ebba3554a2c9401e483b4ed91a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/97.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"824950f8f3e14b41be1aec7a3f3c3d4f"}},"metadata":{}},{"name":"stderr","text":"Unsloth 2025.3.19 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 3072, padding_idx=128004)\n        (layers): ModuleList(\n          (0): LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=8192, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n          )\n          (1): LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear(\n                (base_layer): Linear(in_features=3072, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear(\n                (base_layer): Linear(in_features=3072, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear(\n                (base_layer): Linear(in_features=8192, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=8192, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n          )\n          (2-27): 26 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=8192, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"prompt_temp = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\nWrite a response that appropriately completes the request.\n\n### Instruction:\nClassify the following product review as positive or negative.\n\n### Question:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T04:42:05.028378Z","iopub.execute_input":"2025-04-03T04:42:05.028742Z","iopub.status.idle":"2025-04-03T04:42:05.032438Z","shell.execute_reply.started":"2025-04-03T04:42:05.028714Z","shell.execute_reply":"2025-04-03T04:42:05.031508Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def truncate_text(text, max_length=512, buffer_tokens=50):\n    \"\"\"Truncates the input text to fit within the model's max sequence length.\"\"\"\n    tokenized_text = tokenizer.encode(text, truncation=False)  # Get token IDs\n    max_allowed_length = max_length - buffer_tokens  # Reserve space for response\n\n    if len(tokenized_text) > max_allowed_length:\n        truncated_text = tokenizer.decode(tokenized_text[:max_allowed_length], skip_special_tokens=True)\n        return truncated_text\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T04:42:09.430742Z","iopub.execute_input":"2025-04-03T04:42:09.431075Z","iopub.status.idle":"2025-04-03T04:42:09.435638Z","shell.execute_reply.started":"2025-04-03T04:42:09.431047Z","shell.execute_reply":"2025-04-03T04:42:09.434821Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def classify_review(example):\n    question = truncate_text(example[\"eng_reviews\"])  # Ensure input is within limit\n    input_text = prompt_temp.format(question, \"\")\n\n    inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids=inputs.input_ids,\n            attention_mask=inputs.attention_mask,\n            max_new_tokens=50,\n            use_cache=True,\n        )\n\n    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    predicted_label = prediction.split(\"### Response:\")[-1].strip().upper()  # Extract response\n\n    return {\"predicted_sentiment\": predicted_label}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T05:36:57.010080Z","iopub.execute_input":"2025-04-03T05:36:57.010505Z","iopub.status.idle":"2025-04-03T05:36:57.017353Z","shell.execute_reply.started":"2025-04-03T05:36:57.010464Z","shell.execute_reply":"2025-04-03T05:36:57.016443Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Load dataset (assuming it's a CSV)\ndataset = load_dataset(\"csv\", data_files=\"/kaggle/input/amazon-reviews-for-sentiment-analysis/amazon_review_dataset.csv\")['train']\n\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T04:42:21.895277Z","iopub.execute_input":"2025-04-03T04:42:21.895608Z","iopub.status.idle":"2025-04-03T04:42:22.323576Z","shell.execute_reply.started":"2025-04-03T04:42:21.895580Z","shell.execute_reply":"2025-04-03T04:42:22.322679Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48c83ca06d554020bcf1ede097a65195"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['eng_reviews', 'sentiments'],\n    num_rows: 7763\n})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T05:36:24.827900Z","iopub.execute_input":"2025-04-03T05:36:24.828221Z","iopub.status.idle":"2025-04-03T05:36:24.834313Z","shell.execute_reply.started":"2025-04-03T05:36:24.828195Z","shell.execute_reply":"2025-04-03T05:36:24.833397Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'eng_reviews': \"OnePlus has outdone itself this time, delivering a smartphone that truly lives up to its legacy as a flagship killer. After using it for a week, here are my ratings:  1. Design: 10/10 The slim, boxy design with a matte black finish feels premium and elegant. The in-hand feel is exceptional.  2. AI: 10/10 Packed with all the latest AI features, it’s both innovative and intuitive.  3. OS: 9/10 The return of OxygenOS is a brilliant move! While there are a few bloatware apps, OxygenOS 15 is lightning-fast and smooth.  4. Camera: 9/10 While not flagship-level, the camera performs impressively, capturing excellent detail in most scenarios.  5. Battery: 10/10 The silicon battery is a game-changer, offering 10-11 hours of screen-on time with moderate use—simply outstanding.  6. Processor: 10/10 The Snapdragon 8 Gen 3 delivers optimized, power-efficient performance that feels seamless.  7. Display: 10/10 The display is breathtaking—vivid, sharp, and a delight to use.  Overall, OnePlus 13R is a powerhouse and offers unbeatable value for its price.  Conclusion: The OnePlus 13R is a masterclass in balancing performance, design, and innovation at a competitive price. With its sleek design, cutting-edge AI features, impressive battery life, and smooth performance, it redefines what a flagship killer should be. While the camera isn't quite flagship-level, it holds its own in most scenarios. If you're looking for a phone that offers premium features without breaking the bank, the OnePlus 13R is the one to beat.\",\n 'sentiments': 'POSITIVE'}"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"dataset = dataset.map(classify_review)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T05:37:03.200505Z","iopub.execute_input":"2025-04-03T05:37:03.200811Z","iopub.status.idle":"2025-04-03T06:15:10.566568Z","shell.execute_reply.started":"2025-04-03T05:37:03.200788Z","shell.execute_reply":"2025-04-03T06:15:10.565812Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7763 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75da7adf50594913952434709e601fe9"}},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T06:15:50.331932Z","iopub.execute_input":"2025-04-03T06:15:50.332233Z","iopub.status.idle":"2025-04-03T06:15:50.338460Z","shell.execute_reply.started":"2025-04-03T06:15:50.332208Z","shell.execute_reply":"2025-04-03T06:15:50.337713Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'eng_reviews': \"OnePlus has outdone itself this time, delivering a smartphone that truly lives up to its legacy as a flagship killer. After using it for a week, here are my ratings:  1. Design: 10/10 The slim, boxy design with a matte black finish feels premium and elegant. The in-hand feel is exceptional.  2. AI: 10/10 Packed with all the latest AI features, it’s both innovative and intuitive.  3. OS: 9/10 The return of OxygenOS is a brilliant move! While there are a few bloatware apps, OxygenOS 15 is lightning-fast and smooth.  4. Camera: 9/10 While not flagship-level, the camera performs impressively, capturing excellent detail in most scenarios.  5. Battery: 10/10 The silicon battery is a game-changer, offering 10-11 hours of screen-on time with moderate use—simply outstanding.  6. Processor: 10/10 The Snapdragon 8 Gen 3 delivers optimized, power-efficient performance that feels seamless.  7. Display: 10/10 The display is breathtaking—vivid, sharp, and a delight to use.  Overall, OnePlus 13R is a powerhouse and offers unbeatable value for its price.  Conclusion: The OnePlus 13R is a masterclass in balancing performance, design, and innovation at a competitive price. With its sleek design, cutting-edge AI features, impressive battery life, and smooth performance, it redefines what a flagship killer should be. While the camera isn't quite flagship-level, it holds its own in most scenarios. If you're looking for a phone that offers premium features without breaking the bank, the OnePlus 13R is the one to beat.\",\n 'sentiments': 'POSITIVE',\n 'predicted_sentiment': 'POSITIVE'}"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"label_map = {\"POSITIVE\": 1, \"NEGATIVE\": 0}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T06:15:57.925192Z","iopub.execute_input":"2025-04-03T06:15:57.925542Z","iopub.status.idle":"2025-04-03T06:15:57.929231Z","shell.execute_reply.started":"2025-04-03T06:15:57.925517Z","shell.execute_reply":"2025-04-03T06:15:57.928357Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"dataset = dataset.filter(lambda example: example[\"predicted_sentiment\"] in label_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T06:16:03.257138Z","iopub.execute_input":"2025-04-03T06:16:03.257454Z","iopub.status.idle":"2025-04-03T06:16:03.324060Z","shell.execute_reply.started":"2025-04-03T06:16:03.257428Z","shell.execute_reply":"2025-04-03T06:16:03.323237Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/7763 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1d6072560d74fd98ca3700cb3b19b52"}},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"true_labels = [label_map[label] for label in dataset[\"sentiments\"]]\npredicted_labels = [label_map[label] for label in dataset[\"predicted_sentiment\"]]\n\n# Compute accuracy\naccuracy_metric = evaluate.load(\"accuracy\")\naccuracy = accuracy_metric.compute(predictions=predicted_labels, references=true_labels)\nprint(\"Accuracy:\", accuracy[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T06:16:44.572528Z","iopub.execute_input":"2025-04-03T06:16:44.572862Z","iopub.status.idle":"2025-04-03T06:16:45.375375Z","shell.execute_reply.started":"2025-04-03T06:16:44.572836Z","shell.execute_reply":"2025-04-03T06:16:45.374518Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87cb969c524b49c58cfd63237e3734ab"}},"metadata":{}},{"name":"stdout","text":"Accuracy: 0.8607497101635966\n","output_type":"stream"}],"execution_count":33}]}